---
title: Naive Bayes and Generative Model
date: 2021-10-21 17:17:25
permalink: /pages/ee42b0/
categories:
  - æœºå™¨å­¦ä¹ å…«è‚¡æ–‡
  - Machine Learning Problems
tags:
  - 
---
## Generative v.s. Discrimitive Model
from [csdn](https://blog.csdn.net/Oh_MyBug/article/details/104343641)
<img src="https://raw.githubusercontent.com/emmableu/image/master/generative-model-0.png" width="100%">
simple generative model includes:
- naive bayes 
- LDA (Linear Discrimitative Analysis)
<img src="https://raw.githubusercontent.com/emmableu/image/master/generative-model-1.png" width="100%">

### generative model pros and cons
#### pros
- å®é™…ä¸Šå¸¦çš„ä¿¡æ¯æ¯”åˆ¤åˆ«æ¨¡å‹ä¸°å¯Œ
- ç ”ç©¶å•ç±»é—®é¢˜æ¯”åˆ¤åˆ«æ¨¡å‹çµæ´»æ€§å¼º
- èƒ½ç”¨äºæ•°æ®ä¸å®Œæ•´æƒ…å†µ, åŸºäºæ¦‚ç‡åˆ†å¸ƒçš„å‡è®¾ï¼Œæ‰€éœ€çš„training dataè¾ƒå°‘
- å¾ˆå®¹æ˜“å°†å…ˆéªŒçŸ¥è¯†è€ƒè™‘è¿›å»
- ç¨³å¥å‹å¥½ï¼Œå½“æ•°æ®å‘ˆç°ä¸åŒç‰¹ç‚¹æ—¶ï¼Œåˆ†ç±»æ€§èƒ½ä¸ä¼šå‡ºç°å¤ªå¤§çš„å·®å¼‚å¯¹noiseæ¯”è¾ƒrobust
#### cons
- å®¹æ˜“äº§ç”Ÿé”™è¯¯åˆ†ç±»:Naive Bayesé‡Œé¢å‡è®¾æ¯ä¸ªäº‹ä»¶éƒ½æ˜¯independentçš„ï¼Œæ¯”å¦‚00|01|10 & 11çš„åˆ†ç±»ï¼Œæ ·æœ¬ä¸å‡çš„æ—¶å€™å¯èƒ½ä¼šåˆ†é”™ï¼Œå› ä¸ºmodelå¯èƒ½ä¼šè„‘è¡¥ä¸å­˜åœ¨çš„æƒ…å†µ
- å­¦ä¹ å’Œè®¡ç®—è¿‡ç¨‹æ¯”è¾ƒå¤æ‚


### discrimitive model pros and cons
#### pros
- åˆ†ç±»è¾¹ç•Œæ›´çµæ´»ï¼Œæ¯”ä½¿ç”¨çº¯æ¦‚ç‡æ–¹æ³•æˆ–ç”Ÿæˆæ¨¡å‹å¾—åˆ°çš„æ›´é«˜çº§
- èƒ½æ¸…æ™°çš„åˆ†è¾¨å‡ºå¤šç±»æˆ–æŸä¸€ç±»ä¸å…¶å®ƒç±»ä¹‹é—´çš„å·®å¼‚ç‰¹å¾
- å¯¹äºå¤šfeatureçš„æƒ…å†µï¼Œfeatureä¹‹é—´å¤šæœ‰correlationï¼Œæ¯”èµ·naive bayesï¼Œmodels such as logistic regression is much more robust with correlated features. 
- åˆ¤åˆ«æ¨¡å‹çš„æ€§èƒ½æ¯”ç”Ÿæˆæ¨¡å‹è¦ç®€å•ï¼Œæ¯”è¾ƒå®¹æ˜“å­¦ä¹ 
#### cons
- ä¸èƒ½ååº”è®­ç»ƒæ•°æ®æœ¬èº«çš„ç‰¹æ€§ï¼Œåªèƒ½å‘Šè¯‰ä½ çš„æ˜¯1è¿˜æ˜¯2ï¼Œä¸èƒ½æŠŠæ•´ä¸ªåœºæ™¯æè¿°å‡ºæ¥


## å’ŒDiscrimitiveæ¨¡å‹æ¯”èµ·æ¥ï¼ŒGenerative æ›´å®¹æ˜“overfittingè¿˜æ˜¯underfitting
æ›´å®¹æ˜“overfittingã€‚
this [stack exchange](https://stats.stackexchange.com/questions/91484/do-discriminative-models-overfit-more-than-generative-models) has some very math explanations.  
æ¯”è¾ƒç®€å•çš„è§£é‡Šï¼š 

A generative model is typically overfitting less because it allows the user to put in more side information in the form of class conditionals.

Consider a generative model ğ‘(ğ‘|ğ‘¥)=ğ‘(ğ‘)ğ‘(ğ‘¥|ğ‘). If the class conditionals are mulitvariate normals with shared covariance, this will have a linear decision boundary. Thus, the model by itself is just as powerful as a linear SVM or logistic regression.

However, a discriminative classifier is much more free in the choice of decision function: it just has to find an appropriate hyperplane. The generative classifier however will need much less samples to find good parameters if the assumptions are valid.

Sorry, this is rather handwavy and there is no hard math behind it. But it is an intuition.

## NaÃ¯ve Bayes ç®—æ³•
![](https://raw.githubusercontent.com/emmableu/image/master/202209211513598.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211515403.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211515884.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211516316.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211516595.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211517623.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211518639.png)


## Gaussian Naive Bayes
![](https://raw.githubusercontent.com/emmableu/image/master/202209211519354.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209211555737.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211609031.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209211616842.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211617475.png)

## Naive bayes q&a 
![](https://raw.githubusercontent.com/emmableu/image/master/202209211618798.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209211619300.png)


## NaÃ¯ve Bayes åŸç†
![](https://raw.githubusercontent.com/emmableu/image/master/202209211632512.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209211619428.png)


## Naive Bayes åŸºç¡€å‡è®¾
å‡è®¾æ•°æ®é›†å±æ€§ä¹‹é—´æ˜¯ç›¸å¯¹ç‹¬ç«‹çš„ã€‚

