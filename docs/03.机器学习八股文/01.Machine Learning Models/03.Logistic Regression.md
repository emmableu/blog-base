---
title: Logistic Regression
date: 2021-10-21 17:17:38
permalink: /pages/1eb164/
categories:
  - 机器学习八股文
  - Machine Learning Problems
tags:
  - 
---
[mostly from stanford notes](https://web.stanford.edu/~jurafsky/slp3/5.pdf)


![](https://raw.githubusercontent.com/emmableu/image/master/202209202349541.png)


## 什么是广义线性模型 generalized linear model GLM

![](https://raw.githubusercontent.com/emmableu/image/master/202209140008911.png)





## Components of a probabilistic machine learning classifier
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-0.png)
## Sigmoid function in logistic regression
this type of function is also called classification function or link function. 
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-1.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-2.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-3.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-4.png)

## The cross-entropy loss function
**bernouli distribution**:   
The Bernoulli distribution is a special case of the binomial distribution where a single trial is conducted (so n would be 1 for such a binomial distribution).
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-6.png)


![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-5.png)


## Gradient Descent 
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-7.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-8.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-9.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-10.png)
### The Gradient for Logistic Regression
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-11.png)
### The Stochastic Gradient Descent Algorithm
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-12.png)
### Working through an Example
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-13.png)
### Mini-batch training
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-14.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-15.png)

## Regularization
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-16.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-17.png)

## Multinomial Logistic Regression
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-18.png)
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-19.png)
### Features in Multinomial Logistic Regression
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-20.png)
### Learning in Multinomial Logistic Regression
![](https://raw.githubusercontent.com/emmableu/image/master/logistic-regression-21.png)

## in logistic regression, why we don't use MSE as the loss function?
用mse容易出现多个局部最优解（即非凸函数）
