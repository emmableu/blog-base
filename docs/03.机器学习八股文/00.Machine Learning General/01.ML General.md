---
title: ML Basics
date: 2021-10-21 16:14:02
permalink: /pages/8ca0fe/
categories:
  - 机器学习八股文
tags:
  - 
---


## overfitting v.s. underfitting
- Overfitting occurs when an analysis fits too closely against its training data and may therefore fails to fit unseen data.
- Underfitting is when a data model is unable to capture the relationship between inputs and outputs accurately. Usually, it occurs when the training data or time is not enough.
![](https://raw.githubusercontent.com/emmableu/image/master/ml-basics-0.png)

## How to avoid overfitting:
1. Cross validation to detect overfitting.
2. Train with more data.
3. Data augmentation.
4. Feature selection.
5. Early stop.
6. Regularization.
7. Bagging.

## Cross Validation
In cross validation, data is split into k equally sized folds. One of the fold is used as the validation set and the rest is used to train the model. So a score is obtained. Repeat this process until each fold is used as the validation set. An average of the scores is used to assess the performance of the overall model.





什么是relative entropy/crossentropy,  以及K-L divergence 他们intuition



## how to capture feature interaction
![](https://raw.githubusercontent.com/emmableu/image/master/ml-general-2.png)
