---
title: K-Means Clustering
date: 2021-10-21 17:14:20
permalink: /pages/aed8f8/
categories:
  - 机器学习八股文
  - Machine Learning Models
tags:
  - 
---

## K-means clustering Algorithm

[source](https://tyami.github.io/machine%20learning/k-means-clustering/#k-means-clustering "Permalink")


![2020-10-31-k-means-clustering-1-intro.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-1-intro.png)

K-means clustering is a typical clustering technique. As shown in the figure above, when each cluster is created, the average value of the data within the cluster plays an important role.

The algorithm is not that complicated and easy to understand.

### EM algorithm

The K-means algorithm is an EM algorithm. EM stands for Expectation-Maximization, and it refers to an algorithm that learns data distribution by repeating Expectation and Maximization.

### K-means algorithm
1.  Randomize k random samples of the data as the initial mean of the cluster.
2.  Calculate the distance between each data and each mean.
3.  (Expectation) Assigns each data to the element of the nearest cluster.
4.  (Maximization) Recalculates the mean of the cluster.
5.  Repeat steps 2-4 until there is no change in the clustering results.

![2020-10-31-k-means-clustering-2-steps.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-2-steps.png)

It looks like the picture above. The circles represent each data and the stars represent the mean of the cluster.

Repeat the process of calculating the average, calculating the distance, and assigning the data to the nearest location.

### k

![2020-10-31-k-means-clustering-3-k.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-3-k.png)

The k-means algorithm specifies k in advance. Depending on k, the result changes as above. The appropriate k is determined using the Dunn index or Silhouettes discussed in the [previous post .](https://tyami-github-io.translate.goog/Machine%20learning/clustering/?_x_tr_sl=auto&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=wapp)

## Cons of K-means clustering

K-means clustering has several disadvantages.

![2020-10-31-k-means-clustering-4-cons-1-initial-value.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-4-cons-1-initial-value.png)

First, it is greatly affected by the initial value setting. As in the example above, clustering results may be strange depending on some initial values.

![2020-10-31-k-means-clustering-5-cons-2-size-of-cluster.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-5-cons-2-size-of-cluster.png)

Second, it is affected by the size of the cluster.

![2020-10-31-k-means-clustering-6-cons-3-density-of-cluster.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-6-cons-3-density-of-cluster.png)

Similarly, it is also affected by the density of clusters.

![2020-10-31-k-means-clustering-7-cons-4-shape-of-cluster.png](https://tyami.github.io/assets/images/post/ML/2020-10-31-k-means-clustering/2020-10-31-k-means-clustering-7-cons-4-shape-of-cluster.png)

Finally, it is also affected by the distribution of the data.





## K-means pros and cons
### cons:
- 受初始值和outlier的影响，每次结果不稳定
- 结果不是全局最优而是局部最优
- 无法很好地解决数据簇分布差别较大的情况（比如一类是另一类样本数量的100倍）
- 不太适用于sparse data的分类

### pros:
- 对于大数据集，k-means是相对可伸缩和高效的。
    - 他的计算复杂度是 O(NKt) 接近于线性，其中N是数据对象的数目， K是聚类的族数， t是迭代的轮数。

## How to improve K-Means
### 1.data scaling
![](https://raw.githubusercontent.com/emmableu/image/master/k-means-5.png)
### 2.choose a good value for k:
#### Elbow method
![](https://raw.githubusercontent.com/emmableu/image/master/k-means-3.png)
#### Gap Statistic
![](https://raw.githubusercontent.com/emmableu/image/master/k-means-4.png)

## Why K-Means converges to local optima: loss function decreases monotonically.
![](https://raw.githubusercontent.com/emmableu/image/master/k-means-6.png)
![](https://raw.githubusercontent.com/emmableu/image/master/k-means-7.png)


## how to determine convergence (stop) in practice:
Ideally, if the values in the last two consequent iterations are same then the algorithm is said to have converged. But often people use a less strict criteria for convergence, like, the difference in the values of last two iterations is less than a particular threshold etc,.

