---
title: Classification Metric
date: 2021-11-08 15:43:10
permalink: /pages/4bbcb8/
categories:
  - 机器学习八股文
  - Machine Learning General
tags:
  - 
---
## Basic Classification Metrics
### Why accuracy is not a good metric for unbalanced data: 
假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score（如91%）。此时，虽然Accuracy Score很高，但是意义不大。**当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。**

### Binary classification - Confusion Matrics


![](https://raw.githubusercontent.com/emmableu/image/master/202204101351595.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202204101352098.png)
其中，Precision着重评估**在预测为Positive的所有数据中，真实Positve的数据到底占多少？**Recall着重评估：**在所有的Positive数据中，到底有多少数据被成功预测为Positive?**

举个例子，一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？

如用Precision对系统进行评估，那么其回答的问题就是：

```text
在诊断为癌症的一堆人中，到底有多少人真得了癌症？
```

如用Recall对系统进行评估，那么其回答的问题就是：

```text
在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？
```

如用Accuracy对系统进行评估，那么其回答的问题就是：

```text
在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？
```

**OK，那啥时候应该更注重Recall而不是Precision呢？**

> 当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。



在上述例子里，False Negative是得了癌症的病人没有被诊断出癌症，这种情况是最应该避免的。我们宁可把健康人误诊为癌症 (FP)，也不能让真正患病的人检测不出癌症 (FN) 而耽误治疗离世。在这里，癌症诊断系统的目标是：尽可能提高Recall值，哪怕牺牲一部分Precision。

**那啥时候应该更注重Precision而不是Recall呢？**

> 当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。

以垃圾邮件屏蔽系统为例，垃圾邮件为Positive，正常邮件为Negative，False Positive是把正常邮件识别为垃圾邮件，这种情况是最应该避免的（你能容忍一封重要工作邮件直接进了垃圾箱，被不知不觉删除吗？）。我们宁可把垃圾邮件标记为正常邮件 (FN)，也不能让正常邮件直接进垃圾箱 (FP)。在这里，垃圾邮件屏蔽系统的目标是：尽可能提高Precision值，哪怕牺牲一部分recall。

而F1-score是Precision和Recall两者的综合。

举个更有意思的例子，假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标

尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。

### Multi-Class Classification
![](https://raw.githubusercontent.com/emmableu/image/master/202204101356521.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202204101357554.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202204101358424.png)


### ROC
![](https://raw.githubusercontent.com/emmableu/image/master/202204101354287.png)

### AUC
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-1.png)
#### Interpreting AUC:
One way of interpreting AUC is as **the probability that the model ranks a random positive example more highly than a random negative example**. For example, given the following examples, which are arranged from left to right in ascending order of logistic regression predictions:
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-6.png)
AUC represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example.

AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.


## Precision - Recall Tradeoff
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-2.png)
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-3.png)
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-4.png)
![](https://raw.githubusercontent.com/emmableu/image/master/classification-metrics-5.png)
