---
title: ç™¾é¢ ç­”æ¡ˆ Bai Mian Baimian Solution
date: 2022-09-14 00:15:10
permalink: /pages/e1bf02/
categories:
  - æœºå™¨å­¦ä¹ å…«è‚¡æ–‡
  - Deep Learning Problems
tags:
  - 
---
## ç¬¬1ç«  ç‰¹å¾å·¥ç¨‹

### ä¸ºä»€ä¹ˆéœ€è¦å¯¹æ•°å€¼ç±»å‹çš„ç‰¹å¾åšfeature scalingï¼Ÿ002 â˜…â˜†â˜†â˜†â˜†
Feature scalingï¼Œå¸¸è§çš„ææ³•æœ‰â€œç‰¹å¾å½’ä¸€åŒ–â€(normalization)ã€â€œæ ‡å‡†åŒ–â€(standardization)ï¼Œæ˜¯æ•°æ®é¢„å¤„ç†ä¸­çš„é‡è¦æŠ€æœ¯ï¼Œæœ‰æ—¶ç”šè‡³å†³å®šäº†ç®—æ³•èƒ½ä¸èƒ½workä»¥åŠworkå¾—å¥½ä¸å¥½ã€‚è°ˆåˆ°feature scalingçš„å¿…è¦æ€§ï¼Œæœ€å¸¸ç”¨çš„2ä¸ªä¾‹å­å¯èƒ½æ˜¯ï¼š

- ç‰¹å¾é—´çš„å•ä½ï¼ˆå°ºåº¦ï¼‰å¯èƒ½ä¸åŒï¼Œæ¯”å¦‚èº«é«˜å’Œä½“é‡ï¼Œæ¯”å¦‚æ‘„æ°åº¦å’Œåæ°åº¦ï¼Œæ¯”å¦‚æˆ¿å±‹é¢ç§¯å’Œæˆ¿é—´æ•°ï¼Œä¸€ä¸ªç‰¹å¾çš„å˜åŒ–èŒƒå›´å¯èƒ½æ˜¯[1000, 10000]ï¼Œå¦ä¸€ä¸ªç‰¹å¾çš„å˜åŒ–èŒƒå›´å¯èƒ½æ˜¯[-0.1, 0.2]ï¼Œåœ¨è¿›è¡Œè·ç¦»æœ‰å…³çš„è®¡ç®—æ—¶ï¼Œå•ä½çš„ä¸åŒä¼šå¯¼è‡´è®¡ç®—ç»“æœçš„ä¸åŒï¼Œå°ºåº¦å¤§çš„ç‰¹å¾ä¼šèµ·å†³å®šæ€§ä½œç”¨ï¼Œè€Œå°ºåº¦å°çš„ç‰¹å¾å…¶ä½œç”¨å¯èƒ½ä¼šè¢«å¿½ç•¥ï¼Œä¸ºäº†æ¶ˆé™¤ç‰¹å¾é—´å•ä½å’Œå°ºåº¦å·®å¼‚çš„å½±å“ï¼Œä»¥å¯¹æ¯ç»´ç‰¹å¾åŒç­‰çœ‹å¾…ï¼Œéœ€è¦å¯¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ã€‚
- åŸå§‹ç‰¹å¾ä¸‹ï¼Œå› å°ºåº¦å·®å¼‚ï¼Œå…¶æŸå¤±å‡½æ•°çš„ç­‰é«˜çº¿å›¾ (Contour map) å¯èƒ½æ˜¯æ¤­åœ† (oval) å½¢ï¼Œæ¢¯åº¦æ–¹å‘å‚ç›´äºç­‰é«˜çº¿ï¼Œä¸‹é™ä¼šèµ°zigzagè·¯çº¿ï¼Œè€Œä¸æ˜¯æŒ‡å‘local minimumã€‚é€šè¿‡å¯¹ç‰¹å¾è¿›è¡Œzero-mean and unit-varianceå˜æ¢åï¼Œå…¶æŸå¤±å‡½æ•°çš„ç­‰é«˜çº¿å›¾æ›´æ¥è¿‘åœ†å½¢ï¼Œæ¢¯åº¦ä¸‹é™çš„æ–¹å‘éœ‡è¡æ›´å°ï¼Œæ”¶æ•›æ›´å¿«ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º
![](https://raw.githubusercontent.com/emmableu/image/master/feature-scaling-0.png)
feature scalingçš„æ–¹æ³•å¯ä»¥åˆ†æˆ2ç±»ï¼Œé€è¡Œè¿›è¡Œå’Œé€åˆ—è¿›è¡Œã€‚é€è¡Œæ˜¯å¯¹æ¯ä¸€ç»´ç‰¹å¾æ“ä½œï¼Œé€åˆ—æ˜¯å¯¹æ¯ä¸ªæ ·æœ¬æ“ä½œï¼Œä¸Šå›¾ä¸ºé€è¡Œæ“ä½œä¸­ç‰¹å¾æ ‡å‡†åŒ–çš„ç¤ºä¾‹ã€‚

å…·ä½“åœ°ï¼Œå¸¸ç”¨feature scalingæ–¹æ³•å¦‚ä¸‹
![](https://raw.githubusercontent.com/emmableu/image/master/feature-scaling-1.png)
ä¸Šè¿°4ç§feature scalingæ–¹å¼ï¼Œå‰3ç§ä¸ºé€è¡Œæ“ä½œï¼Œæœ€å1ç§ä¸ºé€åˆ—æ“ä½œã€‚

### ä½•æ—¶åšfeature scaling?
æ¶‰åŠæˆ–éšå«è·ç¦»è®¡ç®—çš„ç®—æ³•ï¼Œæ¯”å¦‚K-meansã€KNNã€PCAã€SVMç­‰ï¼Œä¸€èˆ¬éœ€è¦feature scalingï¼Œå› ä¸º
- zero-meanä¸€èˆ¬å¯ä»¥å¢åŠ æ ·æœ¬é—´ä½™å¼¦è·ç¦»æˆ–è€…å†…ç§¯ç»“æœçš„å·®å¼‚ï¼ŒåŒºåˆ†åŠ›æ›´å¼ºï¼Œå‡è®¾æ•°æ®é›†é›†ä¸­åˆ†å¸ƒåœ¨ç¬¬ä¸€è±¡é™é¥è¿œçš„å³ä¸Šè§’ï¼Œå°†å…¶å¹³ç§»åˆ°åŸç‚¹å¤„ï¼Œå¯ä»¥æƒ³è±¡æ ·æœ¬é—´ä½™å¼¦è·ç¦»çš„å·®å¼‚è¢«æ”¾å¤§äº†ã€‚åœ¨æ¨¡ç‰ˆåŒ¹é…ä¸­ï¼Œzero-meanå¯ä»¥æ˜æ˜¾æé«˜å“åº”ç»“æœçš„åŒºåˆ†åº¦ã€‚
- å°±æ¬§å¼è·ç¦»è€Œè¨€ï¼Œå¢å¤§æŸä¸ªç‰¹å¾çš„å°ºåº¦ï¼Œç›¸å½“äºå¢åŠ äº†å…¶åœ¨è·ç¦»è®¡ç®—ä¸­çš„æƒé‡ï¼Œå¦‚æœæœ‰æ˜ç¡®çš„å…ˆéªŒçŸ¥è¯†è¡¨æ˜æŸä¸ªç‰¹å¾å¾ˆé‡è¦ï¼Œé‚£ä¹ˆé€‚å½“å¢åŠ å…¶æƒé‡å¯èƒ½æœ‰æ­£å‘æ•ˆæœï¼Œä½†å¦‚æœæ²¡æœ‰è¿™æ ·çš„å…ˆéªŒï¼Œæˆ–è€…ç›®çš„å°±æ˜¯æƒ³çŸ¥é“å“ªäº›ç‰¹å¾æ›´é‡è¦ï¼Œé‚£ä¹ˆå°±éœ€è¦å…ˆfeature scalingï¼Œå¯¹å„ç»´ç‰¹å¾ç­‰è€Œè§†ä¹‹ã€‚
- å¢å¤§å°ºåº¦çš„åŒæ—¶ä¹Ÿå¢å¤§äº†è¯¥ç‰¹å¾ç»´åº¦ä¸Šçš„æ–¹å·®ï¼ŒPCAç®—æ³•å€¾å‘äºå…³æ³¨æ–¹å·®è¾ƒå¤§çš„ç‰¹å¾æ‰€åœ¨çš„åæ ‡è½´æ–¹å‘ï¼Œå…¶ä»–ç‰¹å¾å¯èƒ½ä¼šè¢«å¿½è§†ï¼Œå› æ­¤ï¼Œåœ¨PCAå‰åšStandardizationæ•ˆæœå¯èƒ½æ›´å¥½ï¼Œ
![](https://raw.githubusercontent.com/emmableu/image/master/feature-scaling-2.png)
- è¦ç”¨åˆ°gradient descentæ–¹æ³•çš„ç®—æ³•ï¼Œe.g.ï¼Œç¥ç»ç½‘ç»œã€‚
    - æ³¨æ„ï¼Œæ–‡ç« å¼€ç¯‡çš„æ¤­åœ†å½¢å’Œåœ†å½¢ç­‰é«˜çº¿å›¾ï¼Œä»…åœ¨é‡‡ç”¨å‡æ–¹è¯¯å·®(mean square error)çš„çº¿æ€§æ¨¡å‹ä¸Šé€‚ç”¨ï¼Œå…¶ä»–æŸå¤±å‡½æ•°æˆ–æ›´å¤æ‚çš„æ¨¡å‹ï¼Œå¦‚æ·±åº¦ç¥ç»ç½‘ç»œï¼ŒæŸå¤±å‡½æ•°çš„error surfaceå¯èƒ½å¾ˆå¤æ‚ï¼Œå¹¶ä¸èƒ½ç®€å•åœ°ç”¨æ¤­åœ†å’Œåœ†æ¥åˆ»ç”»ï¼Œæ‰€ä»¥ç”¨å®ƒæ¥è§£é‡Šfeature scalingå¯¹æ‰€æœ‰æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸‹é™çš„ä½œç”¨æ˜¯ä¸€ä¸ªç®€åŒ–åçš„è§£é‡Šï¼Œ
- batch normalization: å¯¹äºä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œï¼Œå¯¹è¾“å…¥åšfeature scalingä¹Ÿå¾ˆé‡è¦ï¼Œå› ä¸ºé‡‡ç”¨sigmoidç­‰æœ‰é¥±å’ŒåŒº (saturation point, å¯¼æ•°æ¥è¿‘0ï¼‰ çš„æ¿€æ´»å‡½æ•°ï¼Œå¦‚æœè¾“å…¥åˆ†å¸ƒèŒƒå›´å¾ˆå¹¿ï¼Œå‚æ•°åˆå§‹åŒ–æ—¶æ²¡æœ‰é€‚é…å¥½ï¼Œå¾ˆå®¹æ˜“ç›´æ¥é™·å…¥é¥±å’ŒåŒºï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ï¼Œæ‰€ä»¥ï¼Œéœ€è¦å¯¹è¾“å…¥åšStandardizationæˆ–æ˜ å°„[0,1]ã€[-1,1]ï¼Œé…åˆç²¾å¿ƒè®¾è®¡çš„å‚æ•°åˆå§‹åŒ–æ–¹æ³•ï¼Œå¯¹å€¼åŸŸè¿›è¡Œæ§åˆ¶ã€‚ä½†è‡ªä»æœ‰äº†Batch Normalizationï¼Œæ¯æ¬¡çº¿æ€§å˜æ¢æ”¹å˜ç‰¹å¾åˆ†å¸ƒåï¼Œéƒ½ä¼šé‡æ–°è¿›è¡ŒNormalizationï¼Œä¼¼ä¹å¯ä»¥ä¸å¤ªéœ€è¦å¯¹ç½‘ç»œçš„è¾“å…¥è¿›è¡Œfeature scalingäº†ï¼Ÿä½†ä¹ æƒ¯ä¸Šè¿˜æ˜¯ä¼šåšfeature scalingã€‚


### ä½•æ—¶ä¸åš feature scaling?
- ä¸è·ç¦»è®¡ç®—æ— å…³çš„æ¦‚ç‡æ¨¡å‹ï¼Œä¸éœ€è¦feature scalingï¼Œæ¯”å¦‚Naive Bayesï¼›
- ä¸è·ç¦»è®¡ç®—æ— å…³çš„åŸºäºæ ‘çš„æ¨¡å‹ï¼Œä¸éœ€è¦feature scalingï¼Œæ¯”å¦‚å†³ç­–æ ‘ã€éšæœºæ£®æ—ç­‰ï¼Œæ ‘ä¸­èŠ‚ç‚¹çš„é€‰æ‹©åªå…³æ³¨å½“å‰ç‰¹å¾åœ¨å“ªé‡Œåˆ‡åˆ†å¯¹åˆ†ç±»æ›´å¥½ï¼Œå³åªåœ¨æ„ç‰¹å¾å†…éƒ¨çš„ç›¸å¯¹å¤§å°ï¼Œè€Œä¸ç‰¹å¾é—´çš„ç›¸å¯¹å¤§å°æ— å…³ã€‚ï¼ˆå› ä¸ºå®ƒä»¬ä¸å…³å¿ƒå˜é‡çš„å€¼ï¼Œè€Œæ˜¯å…³å¿ƒå˜é‡çš„åˆ†å¸ƒå’Œå˜é‡ä¹‹é—´çš„æ¡ä»¶æ¦‚ç‡ï¼‰



###  imbalanced data å¤„ç†:
è¿™é‡Œassume æ­£ä¾‹ä¸ºå°‘çš„é‚£ä¸ªdata

#### 1. Undersampling: å»é™¤ä¸€äº›åä¾‹
ä¸‹é‡‡æ ·(under-sampling)é€šè¿‡å‡å°‘åˆ†ç±»ä¸­å¤šæ•°æ ·æœ¬çš„æ•°é‡æ¥å‡è¡¡æ ·æœ¬çš„ç»“æ„ã€‚æœ€ç®€å•ç²—æš´çš„æ–¹æ³•æ˜¯éšæœºåˆ æ‰ä¸€äº›å¤šæ•°ç±»æ ·æœ¬ï¼Œä»£ä»·æ˜¯åˆ é™¤æ ·æœ¬çš„åŒæ—¶ä¹Ÿæœ‰å¯èƒ½åˆ é™¤äº†ä¸€äº›ä¿¡æ¯ï¼Œé€šå¸¸ä½¿ç”¨çš„æ–¹æ³•æœ‰ï¼š

#### clustering
å¯¹äºå¤šæ•°ç±»æ ·æœ¬ï¼Œè®¡ç®—Kè¿‘é‚»çš„ç©ºé—´è·ç¦»(å¦‚æ¬§å¼è·ç¦»)ï¼Œç”¨Kè¿‘é‚»çš„é‡å¿ƒ(centroid)ä»£æ›¿åŸæœ¬çš„Kä¸ªæ ·æœ¬ï¼Œå½¢æˆæ–°çš„å¤šæ•°ç±»æ ·æœ¬ç»„ã€‚å› æ­¤èšç±»æœ€ç»ˆçš„æ ·æœ¬é‡ç”±å°‘æ•°ç±»æ ·æœ¬çš„æ•°é‡å†³å®šã€‚

#### Tomek links

Tomek linksæ˜¯æŒ‡ç›¸åç±»æ ·æœ¬çš„é…å¯¹ï¼Œè¿™æ ·çš„é…å¯¹è·ç¦»éå¸¸è¿‘ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™æ ·çš„é…å¯¹ä¸­ä¸¤ä¸ªæ ·æœ¬çš„å„é¡¹æŒ‡æ ‡éƒ½éå¸¸æ¥è¿‘ï¼Œä½†æ˜¯å±äºä¸åŒçš„ç±»ã€‚å¦‚å›¾æ‰€ç¤ºï¼Œè¿™ä¸€æ–¹æ³•èƒ½å¤Ÿæ‰¾åˆ°è¿™æ ·çš„é…å¯¹ï¼Œå¹¶åˆ é™¤é…å¯¹ä¸­çš„å¤šæ•°ç±»æ ·æœ¬ã€‚ç»è¿‡è¿™æ ·çš„å¤„ç†ï¼Œä¸¤ç±»æ ·æœ¬ä¹‹é—´çš„åˆ†ç•Œçº¿å˜å¾—æ›´åŠ æ¸…æ™°ï¼Œä½¿å°‘æ•°ç±»çš„å­˜åœ¨æ›´åŠ æ˜æ˜¾ã€‚
![](https://raw.githubusercontent.com/emmableu/image/master/imbalanced-data-0.png)
#### 2. Oversampling: å¢åŠ ä¸€äº›æ­£ä¾‹
ä¸Šé‡‡æ ·(over-sampling)æ˜¯å¸¸ç”¨çš„åº”å¯¹ä¸å‡è¡¡æ•°æ®çš„æ–¹æ³•,é€šè¿‡å¢åŠ åˆ†ç±»ä¸­å°‘æ•°ç±»æ ·æœ¬çš„æ•°é‡æ¥å‡è¡¡æ•°æ®ç»“æ„ã€‚å› ä¸ºå…¶å¸¸ç”¨ï¼Œä¹Ÿå‘å±•å‡ºäº†å¾ˆå¤šä¸åŒçš„ä¸Šé‡‡æ ·æŠ€æœ¯ã€‚
#### å¤åˆ¶
æœ€ç®€å•çš„ä¸Šé‡‡æ ·æŠ€æœ¯æ˜¯éšæœºæœ‰æ”¾å›åœ°æŠ½å–å°‘æ•°é‡æ ·æœ¬ï¼Œå¤åˆ¶ä¸€ä»½ååŠ å…¥æ€»æ ·æœ¬ä¸­ã€‚ä½†æ˜¯å¦‚æœæ•°æ®çš„ç‰¹å¾ç»´åº¦è¾ƒå°ï¼Œç®€å•çš„æŠ½å–å¤åˆ¶å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆ(over-fitting)ã€‚ç»è¿‡å¤šå¹´çš„å‘å±•ï¼Œä¸Šé‡‡æ ·æœ‰ä»¥ä¸‹å‡ ç§å¸¸ç”¨çš„æŠ€æœ¯æ¥é¿å…è¿‡æ‹Ÿåˆï¼š
#### åˆæˆæ–°æ ·æœ¬ï¼šSMOTE (Synthetic Minority Over-sampling Technique)åŠå…¶è¡ç”ŸæŠ€æœ¯
ä¸¥æ ¼æ¥è®²ï¼ŒSMOTä¸åº”è¯¥æ”¾åœ¨é‡é‡‡æ ·ä¸­ï¼Œå› ä¸ºæ“ä½œä¸æ¶‰åŠé‡å¤é‡‡æ ·ï¼Œè€Œæ˜¯ä¾æ®ç°æœ‰çš„å°‘æ•°ç±»æ ·æœ¬äººä¸ºåˆ¶é€ ä¸€äº›æ–°çš„å°‘æ•°ç±»æ ·æœ¬ï¼Œæ”¾åœ¨è¿™é‡Œæ˜¯å› ä¸ºSMOTåŠå…¶è¡ç”ŸæŠ€æœ¯ä¹Ÿæ˜¯ä¸Šé‡‡æ ·çš„ä¸€ç§æ–¹å¼ã€‚

å¯¹äºå°‘æ•°ç±»æ ·æœ¬ï¼ŒSMOTåœ¨pä¸ªç»´åº¦ä¸Šæ‰¾åˆ°Kè¿‘é‚»ï¼Œåˆ©ç”¨è¿™Kä¸ªè¿‘é‚»çš„å„é¡¹æŒ‡æ ‡ï¼Œä¹˜ä¸Šä¸€ä¸ª0åˆ°1ä¹‹é—´çš„éšæœºæ•°ï¼Œå°±èƒ½ç»„æˆä¸€ä¸ªæ–°çš„å°‘æ•°ç±»æ ·æœ¬ã€‚å› æ­¤ä¹Ÿå¾ˆå®¹æ˜“å‘ç°ï¼ŒSMOTåªèƒ½å¤Ÿç”Ÿæˆå°‘æ•°ç±»æ ·æœ¬å‡¸åŒ…(convex hall)å†…çš„æ–°æ ·æœ¬ï¼Œè€Œæ°¸è¿œä¸å¯èƒ½ç”Ÿæˆâ€œç¦»ç¾¤â€çš„æ ·æœ¬ã€‚
#### 3. è°ƒæ•´æŸå¤±å‡½æ•°
è°ƒæ•´æŸå¤±å‡½æ•°çš„ç›®çš„æœ¬èº«æ˜¯ä¸ºäº†ä½¿æ¨¡å‹å¯¹å°‘æ•°é‡æ ·æœ¬æ›´åŠ æ•æ„Ÿã€‚è®­ç»ƒä»»ä½•ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹çš„æœ€ç»ˆç›®æ ‡æ˜¯æŸå¤±å‡½æ•°(loss function)çš„æœ€å°åŒ–ï¼Œå¦‚æœèƒ½å¤Ÿåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å¤§é”™åˆ¤å°‘æ•°ç±»æ ·æœ¬çš„æŸå¤±ï¼Œé‚£ä¹ˆæ¨¡å‹è‡ªç„¶è€Œç„¶èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ« å‡ºå°‘æ•°ç±»æ ·æœ¬ã€‚

åœ¨æŸå¤±å‡½æ•°ä¸Šç»™é”™åˆ¤çš„å°‘æ•°ç±»æ ·æœ¬åŠ ä¸Šä¸€ä¸ªæƒ©ç½šç³»æ•°ï¼ŒåŠ å…¥æŸå¤±å‡½æ•°ä¸­ã€‚è¿™æ ·åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šè‡ªç„¶è€Œç„¶åœ°å¯¹å°‘æ•°ç±»æ ·æœ¬æ›´ä¸ºæ•æ„Ÿï¼Œæ¯”å¦‚penalized-SVMå’Œpenalized-LDAè¿™æ ·çš„æ–¹æ³•ã€‚
#### 4. Threshold-moving: é˜ˆå€¼ç§»åŠ¨
å¦‚é¢˜

### overfitting å¤„ç†:

2. Train with more dataï¼Œ å³æ ¹æ®ä¸€äº›å…ˆéªŒçŸ¥è¯†ï¼Œå¯¹åŸå§‹æ•°æ®è¿›è¡Œé€‚å½“å˜æ¢è¾¾åˆ°æ‰©å……æ•°æ®é›†çš„æ•ˆæœã€‚
4. Feature selectionï¼Œæˆ–è€…feature reduction, e.g., PCA
5. Early stop. (e.g., in decision tree)
6. Regularization.
7. Bagging. [ensemble learning](/pages/63f233/)
8. dropout (in Neural network) [link](/pages/63f233/)

### ç¼ºå¤±å€¼ missing data å¤„ç†
å¤„ç†ç¼ºå¤±å€¼çš„æ–¹æ³•ï¼š

é¦–å…ˆäº†è§£æ•°æ®ç¼ºå¤±çš„åŸå› ï¼Œæ ¹æ®åŸå› åˆ¤æ–­ç¼ºå¤±çš„æ•°æ®æ˜¯å¦å…·æœ‰ç‰¹å®šçš„å•†ä¸šæ„ä¹‰ã€‚å¦‚æœä¸å…·å¤‡ä¸šåŠ¡æ„ä¹‰ï¼Œé‚£ä¹ˆå¯ä»¥è¿›è¡Œä»¥ä¸‹æ“ä½œï¼š

1. åˆ é™¤æ•´æ¡è®°å½•ï¼ˆlist-wise deletionï¼‰ï¼šé€‚ç”¨äºç¼ºå¤±å€¼éšæœºåˆ†å¸ƒï¼Œä¸”ç¼ºå¤±å€¼éå¸¸å°‘ï¼Œä¸å½±å“æ•´ä½“æ•°æ®çš„æƒ…å†µã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ç®€å•ï¼Œç¼ºç‚¹æ˜¯å‡å°‘äº†æ ·æœ¬æ•°é‡ã€‚
2. åˆ é™¤å«æœ‰å¤§é‡ç¼ºå¤±å€¼çš„å˜é‡ï¼šå¦‚æœæŸä¸ªå˜é‡åŒ…å«å¤§é‡çš„ç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åˆ é™¤è¿™ä¸ªå˜é‡æ¥ä¿ç•™æ›´å¤šçš„è§‚æµ‹ï¼Œé™¤éè¿™ä¸ªå˜é‡å¯¹äºæ¨¡å‹è€Œè¨€ç‰¹åˆ«é‡è¦ã€‚åº”ç”¨è¿™ä¸ªæ–¹æ³•éœ€è¦æˆ‘ä»¬åœ¨å˜é‡çš„é‡è¦æ€§å’Œè§‚æµ‹çš„æ•°é‡ä¹‹é—´åšæƒè¡¡ã€‚
3. ç”¨æ ‡é‡æ’è¡¥ï¼ˆsingle imputationï¼‰ï¼šå¦‚æœç¼ºå¤±å€¼æ¯”è¾ƒå°‘ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨å¹³å‡å€¼ï¼Œä¸­ä½æ•°ï¼Œä¼—æ•°ç­‰è¿›è¡Œæ’è¡¥ã€‚
4. æ’å€¼æ³•ï¼ˆinterpolationï¼‰ï¼šå…ˆæ±‚å¾—æ’å€¼å‡½æ•°ï¼Œç„¶åå°†ç¼ºå¤±å€¼å¯¹åº”çš„ç‚¹ä»£å…¥æ’å€¼å‡½æ•°å¾—åˆ°ç¼ºå¤±å€¼çš„è¿‘ä¼¼å€¼ã€‚å¸¸è§æ’å€¼æ–¹æ³•æœ‰ linear interpolation, æ‹‰æ ¼æœ—æ—¥æ’å€¼æ³•(Lagrange polynomial)ã€ Newton Polynomial Interpolationã€‚ 
5. ç”¨æ¨¡å‹é¢„æµ‹ï¼ˆmodel-based imputationï¼‰ï¼šé€šè¿‡æ¨¡å‹æ¥ä¼°è®¡ç¼ºå¤±å€¼ï¼Œæ˜¯å¤„ç†ç¼ºå¤±å€¼æ¯”è¾ƒå¤æ‚çš„æ–¹æ³•ã€‚ å¦‚æœç¼ºå¤±å€¼å¾ˆå¤šï¼Œä½†æ˜¯æ¯”è¾ƒé€‚ç”¨æ¨¡å‹é¢„æµ‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸ºä¸¤ç»„ï¼šä¸€ç»„æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œå¦ä¸€ç»„æœ‰ç¼ºå°‘å€¼ã€‚ ç¬¬ä¸€ä¸ªæ•°æ®é›†æˆä¸ºæ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ï¼Œè€Œæœ‰ç¼ºå¤±å€¼çš„ç¬¬äºŒä¸ªæ•°æ®é›†æ˜¯æµ‹è¯•æ•°æ®é›†ï¼Œæœ‰ç¼ºå¤±å€¼çš„å˜é‡è¢«è§†ä¸ºç›®æ ‡å˜é‡ã€‚ æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼Œæ ¹æ®è®­ç»ƒæ•°æ®é›†çš„ç‰¹å¾é¢„æµ‹ç›®æ ‡å˜é‡ï¼Œå¹¶å¡«å……æµ‹è¯•æ•°æ®é›†çš„ç¼ºå¤±å€¼ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çº¿æ€§å›å½’ï¼Œéšæœºæ£®æ—ï¼Œæœ€è¿‘é‚»æ³•ï¼Œé€»è¾‘å›å½’ç­‰å„ç§å»ºæ¨¡æŠ€æœ¯æ¥æ‰§è¡Œæ­¤æ“ä½œã€‚  
è¿™ç§æ–¹æ³•æœ‰ä¸¤ä¸ªç¼ºç‚¹ï¼š  
    - å¦‚æœæ•°æ®é›†ä¸­çš„ç‰¹å¾ä¸æœ‰ç¼ºå°‘å€¼çš„ç‰¹å¾ä¹‹é—´æ²¡æœ‰å…³ç³»ï¼Œé‚£ä¹ˆæ¨¡å‹ä¼°è®¡å°†ä¸ç²¾ç¡®ã€‚
### Word2Vecæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ013
![](https://raw.githubusercontent.com/emmableu/image/master/202209221139166.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221140179.png)





## ç¬¬5ç«  éç›‘ç£å­¦ä¹ 
### Kå‡å€¼èšç±»ç®—æ³•çš„æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ 093 â˜…â˜…â˜†â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209221219602.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221220836.png)


### Kå‡å€¼èšç±»çš„ä¼˜ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•å¯¹å…¶è¿›è¡Œè°ƒä¼˜ï¼Ÿ 094 â˜…â˜…â˜…â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209221222240.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221222136.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221223056.png)


### Kå‡å€¼èšç±»ç¼ºç‚¹æœ‰å“ªäº›ï¼Ÿ 097 â˜…â˜…â˜…â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209221224865.png)
### ä»¥èšç±»ç®—æ³•ä¸ºä¾‹ï¼Œå¦‚ä½•åŒºåˆ†ä¸¤ä¸ªéç›‘ç£å­¦ä¹ ç®—æ³•çš„ä¼˜åŠ£ï¼Ÿ 111 â˜…â˜…â˜…â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209221257114.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221257496.png)







## ç¬¬9ç«  å‰å‘ç¥ç»ç½‘ç»œ
### Effect of batch size, sgd, mini batch
[link](/pages/1f2a0f/#ä¸‰ç±»æ¢¯åº¦ä¸‹é™ç®—æ³•æ¦‚è¿°/)
### å†™å‡ºå¸¸ç”¨æ¿€æ´»å‡½æ•°åŠå…¶å¯¼æ•°ã€‚ 207 â˜…â˜†â˜†â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209160031253.png)


### ç¥ç»ç½‘ç»œè®­ç»ƒæ—¶æ˜¯å¦å¯ä»¥å°†å‚æ•°å…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Ÿ 217 â˜…â˜†â˜†â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209220044455.png)
### ä¸ºä»€ä¹ˆSigmoidå’ŒTanhæ¿€æ´» å‡½æ•°ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±çš„ç°è±¡ï¼Ÿ 208 â˜…â˜…â˜†â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209160032877.png)
### è§£é‡Šå·ç§¯æ“ä½œä¸­çš„ç¨€ç–äº¤äº’å’Œå‚æ•°å…±äº«åŠå…¶ä½œç”¨ã€‚ 223 â˜…â˜…â˜†â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209220045822.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209220046942.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209220046455.png)


### ReLUç³»åˆ—çš„æ¿€æ´»å‡½æ•°çš„ä¼˜ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿä»–ä»¬æœ‰ä»€ä¹ˆå±€é™æ€§ä»¥åŠå¦‚ä½•æ”¹è¿›ï¼Ÿ 209 â˜…â˜…â˜…â˜†â˜†

ä¸‹é¢çš„ç¨€ç–æ€§ä¸»è¦æŒ‡çš„æ˜¯ ç±»ä¼¼ l1 regularization ç›¸æ¯”äºl2çš„ä¼˜ç‚¹ - å¯ä»¥äº§ç”ŸçœŸæ­£çš„ç¨€ç–è§£

![](https://raw.githubusercontent.com/emmableu/image/master/202209160034612.png)
[source](https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks)

Two additional major benefits of ReLUs are sparsity and a reduced likelihood of vanishing gradient. But first recall the definition of a ReLU is â„=max(0,ğ‘), where ğ‘=ğ‘Šğ‘¥+ğ‘

One major benefit is the reduced likelihood of the gradient to vanish. This arises when ğ‘>0. In this regime the gradient has a constant value. In contrast, the gradient of sigmoids becomes increasingly small as the absolute value of x increases. The constant gradient of ReLUs results in faster learning.

The other benefit of ReLUs is sparsity. Sparsity arises when ğ‘â‰¤0. The more such units that exist in a layer the more sparse the resulting representation. Sigmoids on the other hand are always likely to generate some non-zero value resulting in dense representations. Sparse representations seem to be more beneficial than dense representations.

### å¹³æ–¹è¯¯å·®æŸå¤±å‡½æ•°å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°åˆ†åˆ«é€‚åˆä»€ä¹ˆåœºæ™¯ï¼Ÿ 214 â˜…â˜…â˜…â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209220044662.png)


### å¸¸ç”¨çš„æ± åŒ–æ“ä½œæœ‰å“ªäº›ï¼Ÿæ± åŒ–çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ 225 â˜…â˜…â˜…â˜†â˜†


å¹³ç§»ï¼ˆtranslationï¼‰ã€æ—‹è½¬ï¼ˆrotationï¼‰ã€ç¼©æ”¾ï¼ˆscalingï¼‰

![](https://raw.githubusercontent.com/emmableu/image/master/202209220048800.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209220049614.png)
### å·ç§¯ç¥ç»ç½‘ç»œå¦‚ä½•ç”¨äºæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Ÿ 227 â˜…â˜…â˜…â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209220049987.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209220050458.png)
### ResNetçš„æå‡ºèƒŒæ™¯å’Œæ ¸å¿ƒç†è®ºæ˜¯ä»€ä¹ˆï¼Ÿ 230 â˜…â˜…â˜…â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209220050403.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209220052733.png)


## ç¬¬10ç«  å¾ªç¯ç¥ç»ç½‘ç»œ
### å¾ªç¯ç¥ç»ç½‘ç»œä¸å‰é¦ˆç¥ç»ç½‘ç»œç›¸æ¯”æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ 236 â˜…â˜†â˜†â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209220117377.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209220117767.png)
### å¾ªç¯ç¥ç»ç½‘ç»œä¸ºä»€ä¹ˆä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸ï¼Ÿæœ‰å“ªäº›æ”¹è¿›æ–¹æ¡ˆï¼Ÿ 238 â˜…â˜…â˜†â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209220118768.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209220119075.png)

![](https://raw.githubusercontent.com/emmableu/image/master/202209220119783.png)

ã€€Â Â 

### LSTMæ˜¯å¦‚ä½•å®ç°é•¿çŸ­æœŸè®°å¿†åŠŸèƒ½çš„ï¼Ÿ 243 â˜…â˜…â˜†â˜†â˜†
![](https://raw.githubusercontent.com/emmableu/image/master/202209221338297.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221339348.png)

### åœ¨å¾ªç¯ç¥ç»ç½‘ç»œä¸­èƒ½å¦ä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Ÿ 241 â˜…â˜…â˜…â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209221341254.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209221341473.png)


### LSTMé‡Œå„æ¨¡å—åˆ†åˆ«ä½¿ç”¨ä»€ä¹ˆæ¿€æ´»å‡½æ•°ï¼Ÿå¯ä»¥ç”¨å…¶å®ƒçš„æ¿€æ´»å‡½æ•°å—ï¼Ÿ 245 â˜…â˜…â˜…â˜†â˜†

![](https://raw.githubusercontent.com/emmableu/image/master/202209221342449.png)

