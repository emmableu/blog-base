---
title: DL Concepts
date: 2021-10-21 17:06:56
permalink: /pages/b7a5ce/
categories:
  - 机器学习八股文
  - Deep Learning Problems
tags:
  - 
---
DNN为什么要有bias term, bias term的intuition是什么
什么是Back Propagation
梯度消失和梯度爆炸是什么，怎么解决
神经网络初始化能不能把weights都initialize成0
DNN和Logistic Regression的区别
你为什么觉得DNN的拟合能力比Logistic Regression强
how to do hyperparameter tuning in DL/ random search, grid search
Deep Learning有哪些预防overfitting的办法
什么是Dropout，why it works，dropout的流程是什么 (训练和测试时的区别)
什么是Batch Norm, why it works, BN的流程是什么 (训练和测试时的区别)
common activation functions （sigmoid, tanh, relu, leaky relu） 是什么以及每个的优缺点
为什么需要non-linear activation functions
Different optimizers (SGD, RMSprop, Momentum, Adagrad，Adam) 的区别
Batch 和 SGD的优缺点, Batch size的影响
learning rate过大过小对于模型的影响
Problem of Plateau, saddle point
When transfer learning makes sense.