![](https://raw.githubusercontent.com/emmableu/image/master/202209142106241.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209142108313.png)
![](https://raw.githubusercontent.com/emmableu/image/master/202209142109121.png)


[resource](https://leetcode.com/problems/web-crawler-multithreaded/discuss/418126/Python3-Multithreaded-BFS-with-Queue)


## Python Queue API [doc](https://docs.python.org/zh-cn/3/library/queue.html)

[`queue`](https://docs.python.org/zh-cn/3/library/queue.html#module-queue "queue: A synchronized queue class.") 模块实现了多生产者、多消费者队列。这特别适用于消息必须安全地在多线程间交换的线程编程。模块中的 [`Queue`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue "queue.Queue") 类实现了所有所需的锁定语义。

在内部，这三个类型的队列使用锁来临时阻塞竞争线程；然而，它们并未被设计用于线程的重入性处理。

此外，模块实现了一个 "简单的" FIFO 队列类型， [`SimpleQueue`](https://docs.python.org/zh-cn/3/library/queue.html#queue.SimpleQueue "queue.SimpleQueue") ，这个特殊实现为小功能在交换中提供额外的保障。

[`queue`](https://docs.python.org/zh-cn/3/library/queue.html#module-queue "queue: A synchronized queue class.") 模块定义了下列类和异常：

### _class_ `queue.`: `Queue`(_maxsize=0_)

Constructor for a FIFO queue. _maxsize_ is an integer that sets the upperbound limit on the number of items that can be placed in the queue. Insertion will block once this size has been reached, until queue items are consumed. If _maxsize_ is less than or equal to zero, the queue size is infinite.


## Queue对象

队列对象 ([`Queue`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue "queue.Queue"), [`LifoQueue`](https://docs.python.org/zh-cn/3/library/queue.html#queue.LifoQueue "queue.LifoQueue"), 或者 [`PriorityQueue`](https://docs.python.org/zh-cn/3/library/queue.html#queue.PriorityQueue "queue.PriorityQueue")) 提供下列描述的公共方法。

`Queue.qsize()`:

返回队列的大致大小。注意，qsize() > 0 不保证后续的 get() 不被阻塞，qsize() < maxsize 也不保证 put() 不被阻塞。

`Queue.empty()`:

如果队列为空，返回 `True` ，否则返回 `False` 。如果 empty() 返回 `True` ，不保证后续调用的 put() 不被阻塞。类似的，如果 empty() 返回 `False` ，也不保证后续调用的 get() 不被阻塞。


`Queue.full()`:

如果队列是满的返回 `True` ，否则返回 `False` 。如果 full() 返回 `True` 不保证后续调用的 get() 不被阻塞。类似的，如果 full() 返回 `False` 也不保证后续调用的 put() 不被阻塞。

`Queue.put(item, block=True, timeout=None)`

将 _item_ 放入队列。如果可选参数 _block_ 是 true 并且 _timeout_ 是 `None` (默认)，则在必要时阻塞至有空闲插槽可用。如果 _timeout_ 是个正数，将最多阻塞 _timeout_ 秒，如果在这段时间没有可用的空闲插槽，将引发 [`Full`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Full "queue.Full") 异常。反之 (_block_ 是 false)，如果空闲插槽立即可用，则把 _item_ 放入队列，否则引发 [`Full`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Full "queue.Full") 异常 ( 在这种情况下，_timeout_ 将被忽略)。

`Queue.put_nowait(item)`

相当于 `put(item, block=False)`。


`Queue.get(block=True, timeout=None)`:

从队列中移除并返回一个item。如果可选参数 _block_ 是 true 并且 _timeout_ 是 `None` (默认值)，则在必要时阻塞至item可得到。如果 _timeout_ 是个正数，将最多阻塞 _timeout_ 秒，如果在这段时间内项目不能得到，将引发 [`Empty`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Empty "queue.Empty") 异常。反之 (_block_ 是 false) , 如果一个项目立即可得到，则返回一个项目，否则引发 [`Empty`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Empty "queue.Empty") 异常 (这种情况下，_timeout_ 将被忽略)。

POSIX系统3.0之前，以及所有版本的Windows系统中，如果 _block_ 是 true 并且 _timeout_ 是 `None` ， 这个操作将进入基础锁的不间断等待。这意味着，没有异常能发生，尤其是 SIGINT 将不会触发 [`KeyboardInterrupt`](https://docs.python.org/zh-cn/3/library/exceptions.html#KeyboardInterrupt "KeyboardInterrupt") 异常。


`Queue.get_nowait()`

相当于 `get(False)` 。

提供了两个方法，用于支持跟踪 排队的任务 是否 被守护的消费者线程 完整的处理。

`Queue.task_done()`

表示前面排队的任务已经被完成。被队列的消费者线程使用。每个 [`get()`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue.get "queue.Queue.get") 被用于获取一个任务， 后续调用 [`task_done()`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue.task_done "queue.Queue.task_done") 告诉队列，该任务的处理已经完成。

如果 `join()` 当前正在阻塞，在所有条目都被处理后，将解除阻塞(意味着每个 `put()`进队列的条目的 [`task_done()`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue.task_done "queue.Queue.task_done") 都被收到)。

如果被调用的次数多于放入队列中的项目数量，将引发 [`ValueError`](https://docs.python.org/zh-cn/3/library/exceptions.html#ValueError "ValueError") 异常 。

`Queue.join()`

阻塞至队列中所有的元素都被接收和处理完毕。

当条目添加到队列的时候，未完成任务的计数就会增加。每当消费者线程调用 [`task_done()`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue.task_done "queue.Queue.task_done") 表示这个条目已经被回收，该条目所有工作已经完成，未完成计数就会减少。当未完成计数降到零的时候， [`join()`](https://docs.python.org/zh-cn/3/library/queue.html#queue.Queue.join "queue.Queue.join") 阻塞被解除。

如何等待排队的任务被完成的示例：

```python
import threading
import queue

q = queue.Queue()

def worker():
    while True:
        item = q.get()
        print(f'Working on {item}')
        print(f'Finished {item}')
        q.task_done()

# Turn-on the worker thread.
threading.Thread(target=worker, daemon=True).start()

# Send thirty task requests to the worker.
for item in range(30):
    q.put(item)

# Block until all tasks are done.
q.join()
print('All work completed')

```


## 怎样让多个thread完成大量工作

```python
import threading
import queue

q = queue.Queue()

l = threading.Lock()

def worker():
    while True:
        item = q.get()
        print(f'Thread {threading.current_thread().name}, Finished {item}')
        q.task_done()

for item in range(6):
    q.put(item)

for i in range(3):
    t = threading.Thread(target=worker, daemon=True, name=f't{i}')
    t.start()


# Block until all tasks are done.
q.join()
print('All work completed')
```


结果
```
Thread t0, Finished 0
Thread t0, Finished 1
Thread t0, Finished 2
Thread t0, Finished 3
Thread t0, Finished 5
Thread t1, Finished 4
All work completed
```


如果中间加上睡觉
```python
import threading
import queue
import time

q = queue.Queue()

l = threading.Lock()

def worker():
    while True:
        item = q.get()
        print(f'Thread {threading.current_thread().name}, Finished {item}')
        time.sleep(1)
        q.task_done()

for item in range(6):
    q.put(item)

for i in range(3):
    t = threading.Thread(target=worker, daemon=True, name=f't{i}')
    t.start()


# Block until all tasks are done.
q.join()
print('All work completed')
```

结果

```
Thread t0, Finished 0
Thread t1, Finished 1
Thread t2, Finished 2
Thread t0, Finished 3
Thread t1, Finished 4
Thread t2, Finished 5
All work completed
```




## Solution

假设有8个worker

```python
import threading
from queue import Queue

class Solution:
    def crawl(self, startUrl: str, htmlParser: 'HtmlParser') -> List[str]:
        def hostname(url):
            start = len("http://")
            i = start
            while i < len(url) and url[i] != "/":
                i += 1
            return url[start:i]
        
        queue = Queue()
        seen = {startUrl}
        start_hostname = hostname(startUrl)
        seen_lock = threading.Lock()
        
        def worker():
            while True:
                url = queue.get()
                if url is None:
                    return

                for next_url in htmlParser.getUrls(url):
                    if next_url not in seen and hostname(next_url) == start_hostname:
                        seen_lock.acquire()
                        # Acquire lock to ensure urls are no enqueed multiple times
                        if next_url not in seen:
                            seen.add(next_url)
                            queue.put(next_url)
                        seen_lock.release()
                queue.task_done()
        
        num_workers = 8
        workers = []
        queue.put(startUrl)
        
        for i in range(num_workers):
            t = threading.Thread(target=worker)
            t.start()
            workers.append(t)
        
        # Wait until empty
        queue.join()
        
        for i in range(num_workers):
            queue.put(None)
        for t in workers:
            t.join()
        
        return list(seen)
```


