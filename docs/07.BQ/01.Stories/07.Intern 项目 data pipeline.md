---
title: Intern 项目 data pipeline
date: 2022-10-03 21:43:58
permalink: /pages/19501f/
categories:
  - BQ
  - Stories
tags:
  - 
---


没有按时完成 / are right a lot 多方采纳建议 模版
  
## Background
- During my internship with Facebook Feed Ranking team, where I was working on improving our team's PNUF model's offline and online performance, one of the task I needed to do was to add multiple positive-labeled data from another very large dataset. (cold start problem)
- The technical steps to do that is pretty straight-forward - I just find users who only has negative-only labels, and do a join with the original dataset to find the positive labeled samples. Of course there are some other details to handle such as picking only the same amount of negative-labels as the existing positive labels to achieve a balanced sample, etc, but this is the main idea.
- But the thing is both of the two datasets are very big, and doing a join takes up lots of resources.

- with a test-run for a day's data, I estimated the entire data pipeline (need 7 days of data ) need 70 hours, so in total  4 days.  （细节见下，可跳过）
	- I tested it for 1 day and it took 10 hours.
	- And to put the dataset into the model training pipeline it needs to backfill at least 7 days of data.
	- so I needed about 3 more days to complete making the dataset.
	- And model training and offline evaluation takes about another 12 hours. So in total 4 days.


## Challenge

- But when I was backfilling the 7 days of data, the backfill pipeline stopped at the second day, saying that our team have been way over on computational resource quota, and as a result everyone has a very limited quota that's allowed per day. And I was blocked from running any pipeline for 3 days.


### evidence for lack of data
- I immediately submitted a ticket and reached out to the oncall person for this,
	- but she did not respond for an entire day
- My manager have never experienced this before, so suggested me to just wait 3 days, as the task that I was working on was pretty exploratory and our team do not have launch or production deadlines that depend on it.
- But I thought that even if I got un-blocked by the oncall person, I will run into storage issue again if nothing's changed - so I did two things.
- I talked with my other peers, but they all have not experienced similar things before. 
- （如果是错误的决定，就说我这里多等了一会）

## Action 
I reached out to different people:
- a senior engineer in my team: (pipeline cleaning)
	- So the other thing that I did is that I brought this up to a senior engineer in our team - let her know about this resource quota issue that I was experiencing. 
		- And she told me that many of our team members had pipelines that are no longer needed - that are still running - she knows about it but just did not have time to resolve this. 
		- So I just went ahead... (explain later) and prepared a spreadsheet by collecting all of the pipelines that were running in our team, with the stakeholders' names and the amount of times they were running. The senior engineer then used the spreadsheet to suggest people to shut down or delete pipelines that are no longer needed, and used this to track people's progress.

- I made a workplace post and tagged other people in my group to check  if my algorithm was efficient enough. (pipeline optimizaition)
	- Two of my peers mentioned some other updates, including additional pre-filtering and switch the tables before and after the join operation, so select from the larger table and join the smaller. After the oncall un-blocked me the next day, I found that a test run for one day has been decreased to 5 hours.

- I attended the office hour of a very senior person that's overseeing multiple teams in my org.  (pipeline remodeling)
	- I told him about the data table issue that I'm experiencing.
	- He told me that there's another team (called discovery team) in our org that's doing user mining, where they focus on finding the user that has more balanced positive/negative labels, and users who are representative of different user clusters. 
		- they are doing user clustering, 
		- and they have features of all different types of users:
			- expressive users, heavy dislike users, etc
	- he told me that I could use the data tables that the team has generated to see if those users can solve or improve the "cold start" problem.

I decided to work on the pipeline cleaning and pipeline optimization immediately. Because I trust their experience - I believed these will definitely solve the root cause of the problem. 

## Result

- In just about 2 days and a half I got the amount of resources I needed to finish my runs. 
- in the end this has led to a improvement to the prediction accuracy
	- **overall ROC_AUC**: 5% increase, 0.85 -> 0.90
	- **ROC_AUC on cold users** (users with < 1year facebookage): 8% increase, 0.80 -> 0.88
	- **ROC_AUC users with less frequent NUF events** (users with < 1year facebookage): 7% increase, 0.82 -> 0.89
	
	- in 7 days, decreased dislike through rate (dislike over percentage view point view, dislike includes the 9 events I've mentioned) by 4.8%
	
	- as a result increased the like through rate by 3%
- I have learned a lot about how to simplify sql queries, and helped our team cleaned up lots of unneeded resource space for future operations.
- I helped our team cleaned up their pipeline
- I set up a meeting with that group, collected data, wrote a post about steps to be taken for using their user clusters. 


## takeaway
are right a lot
-   Makes good decisions in the face of ambiguity, uncertainty, and/or time pressure
-   Applies experience to determine the best approach
-   Seeks out additional perspective and data to make the best decision
-   Recognizes they are not always right and supports the best idea
-   Recognizes when they are lacking expertise or information in a particular subject area





## obsolete

- So there are 3 distinct moments where I planned or adjusted the plan for the expected time:
- first is when I started, while I did not work on the exact same task, I put a week as this is the amount of time that I took for a similar task before.
- Second is when I realized that backfilling data will take about 3 days. Since it's still within a week's constraint - although a little tight, I just written them down in my 1-1 meeting note with my manager - about the time needed on backfill, and about the . But since I was responsible for my own project and there's not much I need help from him at that time, I just informed him that this is what's going on, and he thought that is a reasonable amount of time as well.
- The third time is when I was blocked at running any pipelines.
