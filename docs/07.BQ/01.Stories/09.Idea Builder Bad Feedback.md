---
title: Idea Builder Bad Feedback
date: 2022-10-03 21:52:48
permalink: /pages/09f065/
categories:
  - BQ
  - Stories
tags:
  - 
---

## Background
During the fall of 2021, I was working on the key user facing part of my example generation project. 
- the key part is that students draw things, such as a trajectory of mario jumping, and they click on a button to see code examples that exactly does that. 

I need a tool that supports everything that a powerpoint or google slides software supports, but also extra things:
- motion trajectories
- saving actors (images) in a specific actor directly to be reused
- capture everything on each slide (actor location, direction, size, etc) to generate code examples. 


## Challenge
80 - 90% feedback was good
- The program is simple and easy to use,
- they found new ideas as they explored more and more aspects of the game while creating the storyboard.


10 - 20% feedback was mildly bad
- It was a little frustrating to use.
- There were many simple things to do that took them a while to get working.


the major goal was to write the paper on how the model generates examples, and whether they were used by the students. 

example usage rate was very high. human raters have found examples were high-quality too. 

However, **I am not satisfied with this, because**
- we lose students if we don't give them a better user experience. 
- we also lose teachers, which I'd say is our top-level, or first-order client, as if they found that their students don't like the software ... 

## Action

As students need to use the software for a follow-up assignment (in 3 weeks), 
- although we don't collect data
- do this would help to show to the teachers that we have made our effort to... 

I talked with the collaboraters and my advisors to make sure we are on the same page that paper writing and system update is of equal importance. 

I reviewed the students' feedback with 2 other independent researchers. 
- thematic analysis
- tag students negative feedback to find recurring themes 

key things students did not like: 
- 3 students mentioned difficulty to use without a tutorial. For example, the trajectory recording system. 
- 4 students mentioned low response speed when page loads. 
- 2 students mentioned data loss. because it uses debounced save, sometimes if students quickly add something to a slide, then change to another slide, information from previous slides was not saved 

I confirmed these with my collaborators, who also gave me additional user-experience improvement ideas, such as including more pre-selected images /assets for students to choose, and use a searchbox for students to find those assets. 

addressing these things:
- 3 students mentioned difficulty to use without a tutorial. For example, the trajectory recording system. 
	- I added a gif on the same trajectory drawing pad when students first opened it. 
- 4 students mentioned low response speed when page loads. 
	- when page load, some data (e.g., actor location data) were retrieved from a mysql database, sometimes incurring an O(n) search in worst-case scenario
	- I changed the database to a mondodb database, where everything can be found as a key-value pair, so O(1) search based on a certain actor id. I tested it and found that 
- 2 students mentioned data loss. because it uses debounced save, sometimes if students quickly add something to a slide, then change to another slide, information from previous slides was not saved 
	- I decreased the timeout set for debouncing, and double checked multiple times to make sure it did not loose data. 

based on feedback from my collaborators, I also added more pre-selected images /assets for students to choose, and use a searchbox for students to find those assets. 


I tested with a student through an after-class study. 

I brought this updated system to my collaborators and advisors. They tested it and found it was ok. 

I brought this system to the teacher. As she did not know the student feedback from the previous assignments yet, 
- I presented the analysis from the previous assignment
- and I presented the new system to her, to ask her if she would feel comfortable to give it to the students in the coming assignment. 

She thought it was ok. We still had about 10 days left. So we deployed the system to the students again.

## Result

voluntary surveys did not give any negative feedback

paper also published on time. 

the coming semester received 0 negative feedback

the teacher is still working with me this semester. In fact she is running a study for me right now. 

the system was stable enough that all teachers from introductory programming courses (7 teachers, 7 classrooms, around 1000) students are using my tool now. 